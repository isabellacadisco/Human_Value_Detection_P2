{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isabellacadisco/Human_Value_Detection_P2/blob/main/tests/P2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d6d2ce0e-3969-49ea-88e4-e6befd630952",
          "showTitle": false,
          "title": ""
        },
        "id": "Jv0eHdmOaEi2"
      },
      "outputs": [],
      "source": [
        "eval_outputs = [[ True, False, False, False, False,  True],\n",
        "       [False, False,  True,  True, False, False]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "912dfc0c-771f-4e32-8f95-4ae473f35e90",
          "showTitle": false,
          "title": ""
        },
        "id": "iu51YXsdaEi3",
        "outputId": "f0dfe0b4-5174-4138-9789-942ef07dc6a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[True, False, False, False, False, True],\n",
              " [False, False, True, True, False, False]]"
            ]
          },
          "execution_count": 2,
          "metadata": {}
        }
      ],
      "source": [
        "eval_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0db33dbb-da18-49b1-8c28-a2159dd062f5",
          "showTitle": false,
          "title": ""
        },
        "id": "9nhAlQNfaEi4"
      },
      "outputs": [],
      "source": [
        "eval_targets = [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        " [0.0, 0.0, 1.0, 1.0, 1.0, 0.0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "dde5a191-c7ff-48da-8fa6-98732392578d",
          "showTitle": false,
          "title": ""
        },
        "id": "LkmJAF5zaEi4",
        "outputId": "a437dcd1-ece6-471f-a2db-6d257c708ba9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, 0.0]]"
            ]
          },
          "execution_count": 4,
          "metadata": {}
        }
      ],
      "source": [
        "eval_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "27ac2f56-7230-493a-8b75-dff847133b62",
          "showTitle": false,
          "title": ""
        },
        "id": "ILOs_j9baEi4"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6e7873ac-f7a4-4dc7-b3f3-df8a4052eec2",
          "showTitle": false,
          "title": ""
        },
        "id": "TZnJLZpWaEi4",
        "outputId": "fd3f6f48-2814-48ba-a660-68532ab8f336"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16666666666666666"
            ]
          },
          "execution_count": 8,
          "metadata": {}
        }
      ],
      "source": [
        "metrics.hamming_loss(eval_targets, eval_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a1603ff9-d083-4f78-9db1-f947638e7e22",
          "showTitle": false,
          "title": ""
        },
        "id": "psJgY4W8aEi4",
        "outputId": "9d2ea0f0-f816-4312-c0bc-14eb5f7f8c5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 9,
          "metadata": {}
        }
      ],
      "source": [
        "metrics.accuracy_score(eval_targets, eval_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9747be5a-f3a6-454e-a8a1-804f0328a27d",
          "showTitle": false,
          "title": ""
        },
        "id": "mSNTK6whaEi5",
        "outputId": "7c74b594-d6d2-4527-f80c-a464e5346b92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "execution_count": 12,
          "metadata": {}
        }
      ],
      "source": [
        "metrics.f1_score(eval_targets, eval_outputs, average='micro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6c57806f-a7e3-486f-a24e-d5895b5ff2ae",
          "showTitle": false,
          "title": ""
        },
        "id": "l9hGDVgOaEi5",
        "outputId": "66d49fdc-f7b6-45a9-ec73-4f2fbd0677ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1592: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "execution_count": 13,
          "metadata": {}
        }
      ],
      "source": [
        "metrics.f1_score(eval_targets, eval_outputs, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b9847c91-5c88-4e63-a37d-3d573e8cadaa",
          "showTitle": false,
          "title": ""
        },
        "id": "QxAjqH4JaEi5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import multilabel_confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e34a8a8f-61ad-45c0-b7e9-59e9f8c9c659",
          "showTitle": false,
          "title": ""
        },
        "id": "9UFITX6RaEi5",
        "outputId": "b5cddec8-6cdf-45ee-b464-6b83baae4926"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[2, 0],\n",
              "        [0, 0]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [0, 1]],\n",
              "\n",
              "       [[1, 0],\n",
              "        [1, 0]],\n",
              "\n",
              "       [[1, 1],\n",
              "        [0, 0]]])"
            ]
          },
          "execution_count": 29,
          "metadata": {}
        }
      ],
      "source": [
        "multilabel_confusion_matrix(eval_targets, eval_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "18b11f44-c9bb-406f-a73d-26567f585b2d",
          "showTitle": false,
          "title": ""
        },
        "id": "RpOTha8HaEi5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3a06f567-0817-4989-b10c-c53f0fc7d3dc",
          "showTitle": false,
          "title": ""
        },
        "id": "kpfYuxAKaEi5",
        "outputId": "cc87a153-ccdb-44ce-a794-c480126fb9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n\nSelf-direction: action       1.00      1.00      1.00         2\n           Achievement       0.00      0.00      0.00         0\n    Security: personal       1.00      1.00      1.00         1\n    Security: societal       1.00      1.00      1.00         1\n   Benevolence: caring       0.00      0.00      0.00         1\n Universalism: concern       0.00      0.00      0.00         1\n\n             micro avg       0.80      0.67      0.73         6\n             macro avg       0.50      0.50      0.50         6\n          weighted avg       0.67      0.67      0.67         6\n           samples avg       0.83      0.72      0.71         6\n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/databricks/python/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(\n",
        "    eval_targets,\n",
        "    eval_outputs,\n",
        "    output_dict=False,\n",
        "    target_names=['Self-direction: action', 'Achievement', 'Security: personal', 'Security: societal', 'Benevolence: caring', 'Universalism: concern']\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a2aa3ac0-4f31-41d1-a712-488158fb28c9",
          "showTitle": false,
          "title": ""
        },
        "id": "GoJIpM2OaEi6"
      },
      "outputs": [],
      "source": [
        "e_t = np.array(eval_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "10daf683-8724-43dd-a01a-e974e65682ac",
          "showTitle": false,
          "title": ""
        },
        "id": "qg60zyKLaEi6",
        "outputId": "0823e5df-8bd7-4bc7-db07-11717f0c61ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 1., 1., 0.],\n",
              "       [1., 0., 0., 0., 0., 1.]])"
            ]
          },
          "execution_count": 38,
          "metadata": {}
        }
      ],
      "source": [
        "e_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "04fa7599-781a-4a12-9297-7f5dc45c876a",
          "showTitle": false,
          "title": ""
        },
        "id": "rc2TMUGaaEi6",
        "outputId": "6e940498-3390-4981-814e-c1b04ad25061"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 1.0, 1.0, 1.0, 0.0],\n",
              " [1.0, 0.0, 0.0, 0.0, 0.0, 1.0]]"
            ]
          },
          "execution_count": 39,
          "metadata": {}
        }
      ],
      "source": [
        "eval_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f849d07d-2497-4a40-828c-a2d494ac1e88",
          "showTitle": false,
          "title": ""
        },
        "id": "NIj8Kx_VaEi6"
      },
      "outputs": [],
      "source": [
        "e_p = np.array(eval_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f40c84fd-a2d6-4e5b-951a-68411e3b1ff2",
          "showTitle": false,
          "title": ""
        },
        "id": "prbND-yYaEi6"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "51d01eef-352e-4fe1-9b4a-a0a918370b01",
          "showTitle": false,
          "title": ""
        },
        "id": "PvRrfTpxaEi7",
        "outputId": "2bdafaed-f8c0-4e45-b8fb-b5860e0e176f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 5,
          "metadata": {}
        }
      ],
      "source": [
        "metrics.accuracy_score(eval_targets, eval_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5d26a85c-94f4-469f-b964-24a083b4aa06",
          "showTitle": false,
          "title": ""
        },
        "id": "MhTVixgzaEi7"
      },
      "outputs": [],
      "source": [
        "y_true_flat = e_t.flatten()\n",
        "y_pred_flat = e_p.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7a68391e-571b-46ec-b010-6b76181b4fc8",
          "showTitle": false,
          "title": ""
        },
        "id": "yANThzLiaEi7",
        "outputId": "39e71556-89bb-4196-889b-f1c4eda3ce0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
              "       1.])"
            ]
          },
          "execution_count": 12,
          "metadata": {}
        }
      ],
      "source": [
        "y_true_flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "49a6ebf9-f26b-4d72-a910-c18a01b5722a",
          "showTitle": false,
          "title": ""
        },
        "id": "gWILCdSUaEi7",
        "outputId": "1c191b9d-78dd-452b-94bb-dbdb589f8ebe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False, False, False,  True, False, False,  True,\n",
              "        True, False, False,  True, False, False, False, False, False])"
            ]
          },
          "execution_count": 13,
          "metadata": {}
        }
      ],
      "source": [
        "y_pred_flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1fd75cbc-0098-4b79-a001-7cd4d8566d15",
          "showTitle": false,
          "title": ""
        },
        "id": "v2M2vsataEi7",
        "outputId": "6c9039b5-f621-4454-f139-2908702ccdfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "execution_count": 14,
          "metadata": {}
        }
      ],
      "source": [
        "metrics.accuracy_score(y_true_flat, y_pred_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1fca3e25-e634-44c0-b20a-b053f43fb6eb",
          "showTitle": false,
          "title": ""
        },
        "id": "s9AgE1FMaEi7",
        "outputId": "54efe577-d66b-49e7-e38c-abcea5e45432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\n\u001b[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%pip install -q -U transformers datasets evaluate accelerate\n",
        "#%pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6ebee189-00d7-433f-9cb0-33ce90def822",
          "showTitle": false,
          "title": ""
        },
        "id": "IMjNprIMaEi7"
      },
      "outputs": [],
      "source": [
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9dc9e79c-3941-43a3-a22a-c5bef5c165e2",
          "showTitle": false,
          "title": ""
        },
        "id": "KhM3B-fbaEi8",
        "outputId": "3c3c3a5c-2584-482e-f73a-9be68243164b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-05-18 16:28:07.770419: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-18 16:28:07.770478: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-18 16:28:07.770504: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-05-18 16:28:07.777376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Importing stock ml libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# for viz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preparing for TPU usage\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# device = xm.xla_device()\n",
        "import copy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9fb978f8-d596-4100-b3bb-cb0ce42ea2a9",
          "showTitle": false,
          "title": ""
        },
        "id": "w1Y6PEKZaEi8"
      },
      "outputs": [],
      "source": [
        "# # Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f9fbbd23-e59e-4f8f-948b-1cb9fa900068",
          "showTitle": false,
          "title": ""
        },
        "id": "Qf5f41cOaEi8",
        "outputId": "227ff120-2396-4aa8-b3db-9610a9dd7187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 18 16:28:28 2024       \r\n+---------------------------------------------------------------------------------------+\r\n| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\r\n|-----------------------------------------+----------------------+----------------------+\r\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n|                                         |                      |               MIG M. |\r\n|=========================================+======================+======================|\r\n|   0  Tesla T4                       Off | 00000001:00:00.0 Off |                  Off |\r\n| N/A   32C    P8               9W /  70W |      5MiB / 16384MiB |      0%      Default |\r\n|                                         |                      |                  N/A |\r\n+-----------------------------------------+----------------------+----------------------+\r\n                                                                                         \r\n+---------------------------------------------------------------------------------------+\r\n| Processes:                                                                            |\r\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n|        ID   ID                                                             Usage      |\r\n|=======================================================================================|\r\n|  No running processes found                                                           |\r\n+---------------------------------------------------------------------------------------+\r\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "800d269d-b21e-49db-8a4c-d312cf7ca4f6",
          "showTitle": false,
          "title": ""
        },
        "id": "0VsgIDL0aEi8"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "arg_training = pd.read_csv(\"/dbfs/mnt/tesi/hs/data_ir/arguments-training.tsv\", delimiter='\\t')\n",
        "label_training = pd.read_csv(\"/dbfs/mnt/tesi/hs/data_ir/labels-training.tsv\", delimiter= '\\t')\n",
        "df_training = pd.merge(arg_training, label_training, how='left', on=\"Argument ID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6e4d24d9-a6b6-42a2-8bd5-03c083e0d11a",
          "showTitle": false,
          "title": ""
        },
        "id": "fYgOYQm9aEi8"
      },
      "outputs": [],
      "source": [
        "# validation\n",
        "arg_validation = pd.read_csv(\"/dbfs/mnt/tesi/hs/data_ir/arguments-validation.tsv\", delimiter='\\t')\n",
        "label_validation = pd.read_csv(\"/dbfs/mnt/tesi/hs/data_ir/labels-validation.tsv\", delimiter= '\\t')\n",
        "df_validation = pd.merge(arg_validation, label_validation, how='left', on=\"Argument ID\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ae2104ee-7310-4aee-87b3-3fa5a05f423f",
          "showTitle": false,
          "title": ""
        },
        "id": "fHYXD8MYaEi8",
        "outputId": "7f450142-bab7-4f69-9d56-b36e0eac61e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.ipykernel/28134/command-1129008497849231-24046021:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  df_training = df_training.append(df_validation, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "df_training = df_training.append(df_validation, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "496eed80-e8f2-4667-99e9-548c20bb4775",
          "showTitle": false,
          "title": ""
        },
        "id": "c0Ilaoq7aEi8"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "arg_test = pd.read_csv(\"/dbfs/mnt/tesi/hs/data_ir/arguments-test.tsv\", delimiter='\\t')\n",
        "label_test = pd.read_csv(\"/dbfs/mnt/tesi/hs/data_ir/labels-test.tsv\", delimiter= '\\t')\n",
        "df_test = pd.merge(arg_test, label_test, how='left', on=\"Argument ID\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b12a6ad9-c67c-4e9b-913a-b9974cc982d2",
          "showTitle": false,
          "title": ""
        },
        "id": "AMLmscCMaEi9"
      },
      "outputs": [],
      "source": [
        "selected_col = ['Conclusion', 'Stance', 'Premise','Self-direction: action', 'Achievement', 'Security: personal', 'Security: societal', 'Benevolence: caring', 'Universalism: concern']\n",
        "\n",
        "subset_train = df_training[selected_col]\n",
        "#subset_val = df_validation[selected_col]\n",
        "subset_test = df_test[selected_col]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f5cebc2d-23cb-47fb-a11c-f6d2e25712fa",
          "showTitle": false,
          "title": ""
        },
        "id": "S4RZPvERaEi9",
        "outputId": "d84234a5-674b-4033-99c5-507346b36170"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Conclusion</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Premise</th>\n",
              "      <th>Self-direction: action</th>\n",
              "      <th>Achievement</th>\n",
              "      <th>Security: personal</th>\n",
              "      <th>Security: societal</th>\n",
              "      <th>Benevolence: caring</th>\n",
              "      <th>Universalism: concern</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We should ban human cloning</td>\n",
              "      <td>in favor of</td>\n",
              "      <td>we should ban human cloning as it will only ca...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Conclusion  ... Universalism: concern\n",
              "0  We should ban human cloning  ...                     0\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {}
        }
      ],
      "source": [
        "subset_train.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "72b51ce8-c708-4704-a02e-7b539f352ea9",
          "showTitle": false,
          "title": ""
        },
        "id": "puWTan4-aEi9"
      },
      "outputs": [],
      "source": [
        "subset_train = subset_train.copy()\n",
        "subset_train['Text'] = subset_train['Stance'] + \" \" + subset_train['Conclusion'] + \" \" + subset_train['Premise']\n",
        "subset_train.drop(labels=['Conclusion','Premise','Stance'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "417f13dd-8e83-44c6-87ea-e58eaaf10cfa",
          "showTitle": false,
          "title": ""
        },
        "id": "nFUXvvs1aEi9",
        "outputId": "36596aa1-dc0c-47b8-bc95-c8ee89dda5f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Self-direction: action</th>\n",
              "      <th>Achievement</th>\n",
              "      <th>Security: personal</th>\n",
              "      <th>Security: societal</th>\n",
              "      <th>Benevolence: caring</th>\n",
              "      <th>Universalism: concern</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>in favor of We should ban human cloning we sho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Self-direction: action  ...                                               Text\n",
              "0                       0  ...  in favor of We should ban human cloning we sho...\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {}
        }
      ],
      "source": [
        "subset_train.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7c01de01-9c23-400d-abb0-74cf9dc38b38",
          "showTitle": false,
          "title": ""
        },
        "id": "rUIHix3MaEi9",
        "outputId": "138b7fa0-ddc2-4a65-fe1a-56c604242274"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in favor of We should ban human cloning we sho...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in favor of We should ban fast food fast food ...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>against We should end the use of economic sanc...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>against We should abolish capital punishment c...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>against We should ban factory farming factory ...</td>\n",
              "      <td>[0, 0, 1, 0, 1, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text                list\n",
              "0  in favor of We should ban human cloning we sho...  [0, 0, 0, 1, 0, 0]\n",
              "1  in favor of We should ban fast food fast food ...  [0, 0, 1, 0, 0, 0]\n",
              "2  against We should end the use of economic sanc...  [0, 0, 0, 1, 0, 0]\n",
              "3  against We should abolish capital punishment c...  [0, 0, 0, 1, 0, 1]\n",
              "4  against We should ban factory farming factory ...  [0, 0, 1, 0, 1, 1]"
            ]
          },
          "execution_count": 12,
          "metadata": {}
        }
      ],
      "source": [
        "subset_train['list'] = subset_train[subset_train.columns[:6]].values.tolist()\n",
        "train_set = subset_train[['Text', 'list']].copy()\n",
        "train_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "78b517de-7b14-49e6-9722-9825dbd5800a",
          "showTitle": false,
          "title": ""
        },
        "id": "hFQzwwxwaEi9"
      },
      "outputs": [],
      "source": [
        "subset_test = subset_test.copy()\n",
        "subset_test['Text'] = subset_test['Stance'] + \" \" + subset_test['Conclusion'] + \" \" + subset_test['Premise']\n",
        "subset_test.drop(labels=['Conclusion','Premise','Stance'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f4bc07c3-7aa0-43d0-8040-87158e371a08",
          "showTitle": false,
          "title": ""
        },
        "id": "kwrrwyulaEi9",
        "outputId": "62e073a9-048a-4f91-f375-df6301511050"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Self-direction: action</th>\n",
              "      <th>Achievement</th>\n",
              "      <th>Security: personal</th>\n",
              "      <th>Security: societal</th>\n",
              "      <th>Benevolence: caring</th>\n",
              "      <th>Universalism: concern</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>against We should end affirmative action affir...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Self-direction: action  ...                                               Text\n",
              "0                       0  ...  against We should end affirmative action affir...\n",
              "\n",
              "[1 rows x 7 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {}
        }
      ],
      "source": [
        "subset_test.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c7badc2b-b8b7-4c79-9262-1e6af1c5c298",
          "showTitle": false,
          "title": ""
        },
        "id": "AaTlWLZtaEjB",
        "outputId": "e79433b1-6afd-47bd-9ee4-63a337d7b7c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>against We should end affirmative action affir...</td>\n",
              "      <td>[0, 1, 1, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in favor of We should end affirmative action a...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in favor of We should ban naturopathy naturopa...</td>\n",
              "      <td>[0, 1, 1, 0, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in favor of We should prohibit women in combat...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in favor of We should ban naturopathy once era...</td>\n",
              "      <td>[0, 1, 1, 1, 1, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text                list\n",
              "0  against We should end affirmative action affir...  [0, 1, 1, 0, 0, 1]\n",
              "1  in favor of We should end affirmative action a...  [0, 1, 0, 0, 0, 1]\n",
              "2  in favor of We should ban naturopathy naturopa...  [0, 1, 1, 0, 0, 1]\n",
              "3  in favor of We should prohibit women in combat...  [0, 1, 0, 0, 0, 0]\n",
              "4  in favor of We should ban naturopathy once era...  [0, 1, 1, 1, 1, 0]"
            ]
          },
          "execution_count": 15,
          "metadata": {}
        }
      ],
      "source": [
        "subset_test['list'] = subset_test[subset_test.columns[:6]].values.tolist()\n",
        "test_set = subset_test[['Text', 'list']].copy()\n",
        "test_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "1413be34-a873-4131-93f5-7f0a5701ea35",
          "showTitle": false,
          "title": ""
        },
        "id": "ytr2DxJGaEjB"
      },
      "outputs": [],
      "source": [
        "# try DISTILBERT\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9bf17229-b07b-4923-bc03-7a3f061c7a14",
          "showTitle": false,
          "title": ""
        },
        "id": "GZTDlN-JaEjB"
      },
      "outputs": [],
      "source": [
        "def max_text_length(df):\n",
        "  df['length'] = df['Text'].apply(lambda x: len(tokenizer.encode(x)))\n",
        "  max_length = df['length'].max()\n",
        "  return max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9eb3d603-c08c-404c-a300-8b14d31fe2e4",
          "showTitle": false,
          "title": ""
        },
        "id": "aeUAgsycaEjB",
        "outputId": "9fd14b72-db98-4dfd-e087-7de73a52a0be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "execution_count": 18,
          "metadata": {}
        }
      ],
      "source": [
        "MAX_LEN = max(max_text_length(train_set), max_text_length(test_set))\n",
        "MAX_LEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "622e34f6-1246-4623-80b1-6b6bdd818421",
          "showTitle": false,
          "title": ""
        },
        "id": "q8ae5MeUaEjB"
      },
      "outputs": [],
      "source": [
        "# variables that will be used later on in the training\n",
        "TRAIN_BATCH_SIZE = 32 #aumentare a 32 (eventualmente vedere 64)\n",
        "VALID_BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "81e48c83-9fa5-47fd-bdec-7ec8e4869f4a",
          "showTitle": false,
          "title": ""
        },
        "id": "20V5wYMHaEjB"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.Text = dataframe.Text\n",
        "        self.targets = self.data.list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        Text = str(self.Text[index])\n",
        "        Text = \" \".join(Text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            Text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            #pad_to_max_length=True, deprecated\n",
        "            padding='max_length',\n",
        "            #return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        #token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            #'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9cccb429-f599-470d-b231-9740a17c1b1c",
          "showTitle": false,
          "title": ""
        },
        "id": "OBJ2oifjaEjC",
        "outputId": "51ef83b1-3c92-4c14-ae74-460fc3994292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (7289, 3)\nTEST Dataset: (1576, 3)\n"
          ]
        }
      ],
      "source": [
        "train_set = train_set.reset_index(drop=True)\n",
        "test_set = test_set.reset_index(drop=True)\n",
        "print(\"TRAIN Dataset: {}\".format(train_set.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_set.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0bcef65d-7a66-42f5-862c-8d8b0e925c83",
          "showTitle": false,
          "title": ""
        },
        "id": "Or6c59vOaEjC"
      },
      "outputs": [],
      "source": [
        "training_set = CustomDataset(train_set, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_set, tokenizer, MAX_LEN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "39d4700d-d55e-4c99-9427-455fefb66368",
          "showTitle": false,
          "title": ""
        },
        "id": "aqcZUZvBaEjC"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d45a5c12-773d-472c-8835-e6f8fa754970",
          "showTitle": false,
          "title": ""
        },
        "id": "Uflc68B_aEjC",
        "outputId": "2a05358c-2412-43dc-b03f-8cae604dead5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBERTClass(\n",
              "  (l1): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 24,
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "class DistilBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBERTClass, self).__init__()\n",
        "        self.l1 = transformers.DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 6)\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "        outputs = self.l1(ids, attention_mask=mask)\n",
        "        output_1 = outputs.last_hidden_state[:, 0, :]  # DistilBERT doesn't have pooler_output; use the [CLS] token\n",
        "\n",
        "        output_2 = self.l2(output_1)\n",
        "        output = self.l3(output_2)\n",
        "        return output\n",
        "\n",
        "model = DistilBERTClass()\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4532d92b-fd0b-441c-bdb8-5ffa582d55f8",
          "showTitle": false,
          "title": ""
        },
        "id": "mgzrBzaiaEjC"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d906d669-d2b8-4e21-9ec2-000e4dac2b0d",
          "showTitle": false,
          "title": ""
        },
        "id": "2UKrhgt0aEjC"
      },
      "outputs": [],
      "source": [
        "# optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e76871bc-1596-4943-adc4-ebe390abce4d",
          "showTitle": false,
          "title": ""
        },
        "id": "ap-CmDyoaEjC"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    t_fin_targets=[]\n",
        "    t_fin_outputs=[]\n",
        "\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        #token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        # forward\n",
        "        outputs = model(ids, mask) #, token_type_ids)\n",
        "\n",
        "        t_fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "        # apply SIGMOID to get multilabel predictions\n",
        "        t_fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "\n",
        "        #optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        #if _%2000==0:\n",
        "         #   print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # clipping\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "    return t_fin_outputs, t_fin_targets, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0544af88-1706-45b8-89a2-c90e60974b81",
          "showTitle": false,
          "title": ""
        },
        "id": "D7dRSY-_aEjC"
      },
      "outputs": [],
      "source": [
        "def validation(epoch):\n",
        "    model.eval()\n",
        "\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "\n",
        "    with torch.no_grad(): #disable gradient calculation, useful for evaluation\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            #token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "            outputs = model(ids, mask) #, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "219968b6-abe9-4c97-940f-eff9c1f33876",
          "showTitle": false,
          "title": ""
        },
        "id": "Uv4dwkjgaEjD"
      },
      "outputs": [],
      "source": [
        "metrics_train_eval = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d2102b2c-8830-4cd7-bae1-1c4e643fea1d",
          "showTitle": false,
          "title": ""
        },
        "id": "pjpUl08PaEjD",
        "outputId": "4d928a9a-a3c8-4241-e9cf-de38cf9eb2ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\nTrain Accuracy Score = 0.7980289934604655\nTrain F1 Score (Micro) = 0.6258630183404633\nTrain F1 Score (Macro) = 0.6041957464797897\nTrain loss = 0.4442975253128169\nEval Accuracy Score = 1.0\nEval F1 Score (Micro) = 0.6040324256911247\nEval F1 Score (Macro) = 0.5732223624621168\n-------------------------------------------------------------------\nEpoch: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "com.databricks.backend.common.rpc.CommandCancelledException\n",
              "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:103)\n",
              "\tat scala.Option.getOrElse(Option.scala:189)\n",
              "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:103)\n",
              "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)\n",
              "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
              "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)\n",
              "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)\n",
              "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:430)\n",
              "\tat scala.Option.getOrElse(Option.scala:189)\n",
              "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:430)\n",
              "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1225)\n",
              "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:958)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
              "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
              "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:67)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
              "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:67)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
              "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:67)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
              "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:67)\n",
              "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:915)\n",
              "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:672)\n",
              "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:696)\n",
              "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
              "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
              "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
              "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
              "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:696)\n",
              "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:749)\n",
              "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:554)\n",
              "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
              "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
              "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
              "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
              "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
              "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
              "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
              "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
              "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
              "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
              "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
              "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n",
              "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)\n",
              "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)\n",
              "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)\n",
              "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)\n",
              "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)\n",
              "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
              "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
              "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
              "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n",
              "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)\n",
              "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)\n",
              "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)\n",
              "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)\n",
              "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)\n",
              "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)\n",
              "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
              "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
              "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
              "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
              "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
              "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
              "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
              "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
              "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
              "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
              "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
              "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
              "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
              "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
              "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
              "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
              "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
              "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
              "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
              "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
              "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
              "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
              "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
              "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
              "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
              "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
              "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)\n",
              "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)\n",
              "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
              "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)\n",
              "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)\n",
              "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
              "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)\n",
              "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)\n",
              "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)\n",
              "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)\n",
              "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
              "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
              "\tat java.lang.Thread.run(Thread.java:750)"
            ]
          },
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "addedWidgets": {},
              "arguments": {},
              "datasetInfos": [],
              "jupyterProps": null,
              "metadata": {
                "errorSummary": "Cancelled"
              },
              "removedWidgets": [],
              "sqlProps": null,
              "stackFrames": [
                "com.databricks.backend.common.rpc.CommandCancelledException",
                "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:103)",
                "\tat scala.Option.getOrElse(Option.scala:189)",
                "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2(SequenceExecutionState.scala:103)",
                "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$2$adapted(SequenceExecutionState.scala:100)",
                "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
                "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:100)",
                "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:714)",
                "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:430)",
                "\tat scala.Option.getOrElse(Option.scala:189)",
                "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:430)",
                "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1225)",
                "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:958)",
                "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
                "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
                "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
                "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
                "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
                "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
                "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:67)",
                "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
                "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
                "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:67)",
                "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
                "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
                "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:67)",
                "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
                "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
                "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:67)",
                "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:915)",
                "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:672)",
                "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:696)",
                "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
                "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
                "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
                "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
                "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
                "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
                "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
                "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
                "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
                "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
                "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
                "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
                "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:696)",
                "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:749)",
                "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:554)",
                "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
                "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
                "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
                "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
                "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
                "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
                "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
                "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
                "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
                "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
                "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
                "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
                "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
                "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
                "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
                "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
                "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
                "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
                "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
                "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
                "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
                "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)",
                "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)",
                "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)",
                "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)",
                "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)",
                "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)",
                "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
                "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
                "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
                "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)",
                "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)",
                "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)",
                "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)",
                "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)",
                "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)",
                "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)",
                "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
                "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
                "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
                "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
                "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
                "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
                "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
                "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
                "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
                "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
                "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
                "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
                "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
                "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
                "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
                "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
                "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
                "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
                "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
                "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
                "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
                "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
                "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
                "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
                "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
                "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
                "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)",
                "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)",
                "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
                "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)",
                "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)",
                "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
                "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)",
                "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)",
                "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)",
                "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)",
                "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
                "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
                "\tat java.lang.Thread.run(Thread.java:750)"
              ],
              "type": "baseError"
            }
          }
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print(f'Epoch: {epoch}')\n",
        "\n",
        "    # training ----------------------------------------------------------------\n",
        "    train_outputs, train_targets, train_loss = train(epoch)\n",
        "    # put to 1 predictions with value >= 0.5\n",
        "    train_outputs = np.array(train_outputs) >= 0.5\n",
        "\n",
        "    train_outputs_flat = train_outputs.flatten()\n",
        "    train_targets_flat = np.array(train_targets).flatten()\n",
        "\n",
        "    train_accuracy = metrics.accuracy_score(train_targets_flat, train_outputs_flat)\n",
        "    train_f1_score_micro = metrics.f1_score(train_targets, train_outputs, average='micro')\n",
        "    train_f1_score_macro = metrics.f1_score(train_targets, train_outputs, average='macro')\n",
        "\n",
        "    metrics_train_eval[epoch] = {'Train Accuracy Score' : train_accuracy,\n",
        "                        'Train F1 Score (Micro)' : train_f1_score_micro,\n",
        "                        'Train F1 Score (Macro)' : train_f1_score_macro}\n",
        "\n",
        "    print(f\"Train Accuracy Score = {train_accuracy}\")\n",
        "    print(f\"Train F1 Score (Micro) = {train_f1_score_micro}\")\n",
        "    print(f\"Train F1 Score (Macro) = {train_f1_score_macro}\")\n",
        "    print(f\"Train loss = {train_loss}\")\n",
        "\n",
        "\n",
        "    # validation --------------------------------------------------------------\n",
        "\n",
        "    eval_outputs, eval_targets = validation(epoch)\n",
        "    # put to 1 predictions with value >= 0.5\n",
        "    eval_outputs = np.array(eval_outputs) >= 0.5\n",
        "\n",
        "\n",
        "    eval_outputs_flat = eval_outputs.flatten()\n",
        "    eval_targets_flat = np.array(eval_targets).flatten()\n",
        "\n",
        "    eval_accuracy = metrics.accuracy_score(eval_targets_flat, eval_targets_flat)\n",
        "\n",
        "    #eval_accuracy = metrics.accuracy_score(eval_targets, eval_outputs)\n",
        "    eval_f1_score_micro = metrics.f1_score(eval_targets, eval_outputs, average='micro')\n",
        "    eval_f1_score_macro = metrics.f1_score(eval_targets, eval_outputs, average='macro')\n",
        "\n",
        "    metrics_train_eval[epoch].update({\n",
        "        'Eval Accuracy Score': eval_accuracy,\n",
        "        'Eval F1 Score (Micro)': eval_f1_score_micro,\n",
        "        'Eval F1 Score (Macro)': eval_f1_score_macro\n",
        "    })\n",
        "\n",
        "    print(f\"Eval Accuracy Score = {eval_accuracy}\")\n",
        "    print(f\"Eval F1 Score (Micro) = {eval_f1_score_micro}\")\n",
        "    print(f\"Eval F1 Score (Macro) = {eval_f1_score_macro}\")\n",
        "\n",
        "    # Adjust the learning rate\n",
        "    #scheduler.step()\n",
        "\n",
        "    print('-------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "61a4da38-1b53-4bcc-a8af-4fb573ba47b0",
          "showTitle": false,
          "title": ""
        },
        "id": "0rThTkvpaEjD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "P2_databricks_3",
      "widgets": {}
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}